---
title: "Kernel Classfication - 10/23"
output:
  pdf_document: default
  html_notebook: default
---

# Rice Seed Classification

On this R markdown file, we'll be investigating a [Rice seed classification dataset found on Kaggle.](https://www.kaggle.com/datasets/mssmartypants/rice-type-classification)

(Link for pdf viewers: https://www.kaggle.com/datasets/mssmartypants/rice-type-classification)

The dataset has two classes to categorize. A "0" indicates a Gonen rice seed (commonly found and produced in Northwest Turkey) and "1" for jasmine rice. This is tied to the class attribute of the dataset.

## Data Exploration & Train/Test

```{r}
# Data Exploration - Taking a look at min and max areas as well.
df <- read.csv("riceClassification.csv", header = TRUE)
str(df)
head(df)
tail(df)
class_occur <- data.frame(table(df$Class))
print(class_occur)
print(subset(df, Area == max(Area)))
print(subset(df, Area == min(Area)))

## Split into train/test/validate
set.seed(1234)
groups <- c(train=0.6, test=0.2, validate=0.2)
i <- sample(cut(1:nrow(df), nrow(df)*cumsum(c(0,groups)), labels = names(groups)))
train <- df[i=="train",]
test <- df[i=="test",]
vald <- df[i=="validate",]
str(train)
```
It looks like we have a much more equal split of gonen/jasmine rice, which is a pleasure to see after fiddling around with wine and spotify song datasets that seems so scattered. However, I still don't have any idea of how gonen and jasmine rice differ! Luckily we have some kernel methods to sift through.

```{r}
par(mfrow = c(1,2))
plot(train$Class, train$Area, data=train, main = "Area", varwidth=TRUE)
plot(train$Class, train$Roundness, data=train, main = "Roundness", varwidth=TRUE)
```

## SVM Regression

```{r}
library(e1071)

svm1 <- svm(Class~., data=train, kernel="linear" , cost=10, scale = TRUE)
summary(svm1)

```

Let's try some tuning

```{r}
tune_svm1 <- tune(svm, Class~., data=vald, kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune_svm1)
```

Let's make a prediction based on our best model for svm1.

```{r}
pred <- predict(tune_svm1$best.model, newdata=test)
options(max.print = 100) #limit output of table pred function
table(pred, test$Class)
```


Let's try meddling with our kernel types.

```{r}
svm2 <- svm(Class~., data=train, kernel="polynomial" , cost=10, scale = TRUE)
summary(svm2)

#prediction
pred <- predict(svm2, newdata=test)
```

And radial kernels...

```{r}
svm3 <- svm(Class~., data=train, kernel="radial" , cost=10, gamma=1, scale = TRUE)
summary(svm3)

pred <- predict(svm3, newdata=test)
```

Let's tune our hyper parameters

```{r}
set.seed(1234)
tune.out <- tune(svm, Class~., data=vald, kernel="radial", ranges=list(cost =c(0.1,1,10,100,1000), gamma =c(0.5,1,2,3,4)))
summary(tune.out)
```

Finally, from the tuned data output, we can see that we get best results with a cost = 10 and a gamma = 0.5.

```{r}
svm_final <- svm(Class~., data = train, kernel="radial", cost = 10, gamma = 0.5, scale = TRUE)
summary(svm_final)

pred <- predict(svm_final, newdata = test)
```


## Reflections

Let's take a look at how these kernels work.

Linear Kernels: Linear kernels are most advantageous when the data is linearly classifiable, so drawing a straight line across the plot would adequately separate the dataset. Commonly used when there are many features in a dataset.

Polynomial Kernels: Data is rarely ever linearly separable, so polynomial kernels add another dimension to allow so that we can find another way to fit the data to become linearly separable. 

Radial Kernels: Radial kernels introduce an additional hyperparameter, the gamma parameter. Gamma manipulates the boundary of the hyperplane where lower values give sharper peaks and higher gamma values give more rounded peaks. Rounded peaks are more susceptible to points closer to the boundary, so we have a bias-variance tradeoff with the gamma value where we have a lower bias - higher variance with smaller gamma values (as we see with this rice classification) and a higher bias - lower variance with larger gamma values.

This was a fun dataset to mess around with. I think one of the most confusing factors is the gonen rice class itself. Google searches on gonen rice don't yield any real information other than a wikipedia article on the city of GÃ¶nen and a passing remark about it's rice production. So quite honesty Perhaps I'll have to interview some Turks over a nice plate of Turkish food to gather some more information.